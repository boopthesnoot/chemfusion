general:
  random_seed:
  proj_path: /data/user/mikhaillebedev/nlp_graphs/GraphTextModel/molvae_regr/
  tmp_path: tmp
  pad_symbol: _
  fixed_random_seed: 3407
  eval_size: 3000
  gpus: 1
  num_buckets: 24

run:
  n_runs: 10
  reco_dataset: moses # freesolv #
  regr_dataset: freesolv
  regr_vanilla: True
  reco: False
  regr_with_reco: False

model:
  graph: True
  str: True
  noise: False
  device: gpu

layers:
  gconv1: 100
  gconv2: 200
  latent_dim: 2048 # 512 # 292 latent space dimensionality
  gru: {'hidden_size': 501, 'num_layers': 3, 'batch_first': True}
  regr: 30

  d_premodel: 512
  d_model: 512
  num_layers: 6
  num_heads: 8
  d_feedforward: 2048
  h_feedforward: 512
  activation: "gelu"
  max_seq_len: 512
  default_dropout: 0.1

regression:
  batch_size: 16
  acc_batches: 1
  epochs: 20
  dropout: 0.2
  early_stop: {'tol': 0.00001, 'rounds': 100, 'task': 'min'}
  optim: {'lr': 3e-4, 'weight_decay': 1e-6} # {'lr': 4e-5, 'weight_decay': 1e-6}
  clip_grad: 1.0
#  verbose:
#    batch: 0
#    epoch: 1

reconstruction:
  sample_size:
  augment: True
  batch_size: 1024
  epochs: 1
  optim: {'lr': 5e-4, 'weight_decay': 1e-6}
  verbose:
    batch: 20
    epoch: 1
